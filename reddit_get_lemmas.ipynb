{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.0.6-cp37-cp37m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.4-cp37-cp37m-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (449 kB)\n",
      "\u001b[K     |████████████████████████████████| 449 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./anaconda3/lib/python3.7/site-packages (from spacy) (2.11.2)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Downloading thinc-8.0.3-cp37-cp37m-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading spacy_legacy-3.0.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 7.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (18 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/lib/python3.7/site-packages (from spacy) (4.50.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp37-cp37m-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.7/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in ./anaconda3/lib/python3.7/site-packages (from spacy) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.7/site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.7/site-packages (from spacy) (2.24.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./anaconda3/lib/python3.7/site-packages (from spacy) (1.19.2)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./anaconda3/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5; python_version < \"3.8\" in ./anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.0)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in ./anaconda3/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107095 sha256=e5fc02c128b462b4dafae2680ab519750134290f3b2a3683ba4ead12f724c057\n",
      "  Stored in directory: /Users/angelicabosko/Library/Caches/pip/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
      "Successfully built smart-open\n",
      "Installing collected packages: pydantic, catalogue, srsly, cymem, murmurhash, preshed, wasabi, blis, thinc, spacy-legacy, smart-open, typer, pathy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 cymem-2.0.5 murmurhash-1.0.5 pathy-0.5.2 preshed-3.0.5 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee72f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angelicabosko/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/angelicabosko/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/angelicabosko/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "# NOTE: stopwords include pronouns! TODO: make custom stop words list?\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c18f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "keep_stop = set(['she', 'her', 'hers', 'herself'])\n",
    "mod_stop_words = stop_words - keep_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3524986",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3825917",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_corpus = pickle.load(open(\"reddit_full_cleaned.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1a770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>time created</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Why the fuck would you be friends with an ex?</td>\n",
       "      <td>1451606442</td>\n",
       "      <td>fuck would friends ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Great story full of RP truths. Thanks. Conside...</td>\n",
       "      <td>1451606479</td>\n",
       "      <td>great story full rp truths thanks consider mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Lets suss this out. \\n\\nFor one; she's either ...</td>\n",
       "      <td>1451606497</td>\n",
       "      <td>lets suss one shes either got high paying job ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Sounds like you may need some more treatment f...</td>\n",
       "      <td>1451606532</td>\n",
       "      <td>sounds like may need treatment anxiety crucial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>hack her phone or fb, its the only way you'll ...</td>\n",
       "      <td>1451606539</td>\n",
       "      <td>hack her phone fb way youll truly know think h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574679</th>\n",
       "      <td>technews</td>\n",
       "      <td>PLEASE! I GET LIKE 3Mb/s I NEEEED THIS</td>\n",
       "      <td>1483147728</td>\n",
       "      <td>please get like 3mbs neeeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574680</th>\n",
       "      <td>technews</td>\n",
       "      <td>Took some screenshots if it gets removed avail...</td>\n",
       "      <td>1483189543</td>\n",
       "      <td>took screenshots gets removed available httpii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574681</th>\n",
       "      <td>technews</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1483199435</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574682</th>\n",
       "      <td>technews</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>1483205392</td>\n",
       "      <td>best tldr could make originalhttpwwwreuterscom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574683</th>\n",
       "      <td>technews</td>\n",
       "      <td>Good, LCD prices have been stagnant too long d...</td>\n",
       "      <td>1483215756</td>\n",
       "      <td>good lcd prices stagnant long due lack competi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574684 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                            comment  \\\n",
       "0       TheRedPill     Why the fuck would you be friends with an ex?    \n",
       "1       TheRedPill  Great story full of RP truths. Thanks. Conside...   \n",
       "2       TheRedPill  Lets suss this out. \\n\\nFor one; she's either ...   \n",
       "3       TheRedPill  Sounds like you may need some more treatment f...   \n",
       "4       TheRedPill  hack her phone or fb, its the only way you'll ...   \n",
       "...            ...                                                ...   \n",
       "574679    technews             PLEASE! I GET LIKE 3Mb/s I NEEEED THIS   \n",
       "574680    technews  Took some screenshots if it gets removed avail...   \n",
       "574681    technews                                          [removed]   \n",
       "574682    technews  This is the best tl;dr I could make, [original...   \n",
       "574683    technews  Good, LCD prices have been stagnant too long d...   \n",
       "\n",
       "        time created                                       cleaned_text  \n",
       "0         1451606442                              fuck would friends ex  \n",
       "1         1451606479  great story full rp truths thanks consider mak...  \n",
       "2         1451606497  lets suss one shes either got high paying job ...  \n",
       "3         1451606532  sounds like may need treatment anxiety crucial...  \n",
       "4         1451606539  hack her phone fb way youll truly know think h...  \n",
       "...              ...                                                ...  \n",
       "574679    1483147728                        please get like 3mbs neeeed  \n",
       "574680    1483189543  took screenshots gets removed available httpii...  \n",
       "574681    1483199435                                            removed  \n",
       "574682    1483205392  best tldr could make originalhttpwwwreuterscom...  \n",
       "574683    1483215756  good lcd prices stagnant long due lack competi...  \n",
       "\n",
       "[574684 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db52d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_comments = comments_corpus['cleaned_text']\n",
    "\n",
    "lemmatized = [[lmtzr.lemmatize(word) for word in word_tokenize(s)]\n",
    "              for s in cleaned_comments]\n",
    "\n",
    "empty_list = list()\n",
    "for lemmas in lemmatized:\n",
    "    empty_list.append(' '.join(lemmas))\n",
    "    \n",
    "\n",
    "comments_corpus['lemmas'] = lemmatized\n",
    "comments_corpus['lemmas_str'] = empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b381aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>time created</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lemmas_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Why the fuck would you be friends with an ex?</td>\n",
       "      <td>1451606442</td>\n",
       "      <td>fuck would friends ex</td>\n",
       "      <td>[fuck, would, friend, ex]</td>\n",
       "      <td>fuck would friend ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Great story full of RP truths. Thanks. Conside...</td>\n",
       "      <td>1451606479</td>\n",
       "      <td>great story full rp truths thanks consider mak...</td>\n",
       "      <td>[great, story, full, rp, truth, thanks, consid...</td>\n",
       "      <td>great story full rp truth thanks consider maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Lets suss this out. \\n\\nFor one; she's either ...</td>\n",
       "      <td>1451606497</td>\n",
       "      <td>lets suss one shes either got high paying job ...</td>\n",
       "      <td>[let, sus, one, shes, either, got, high, payin...</td>\n",
       "      <td>let sus one shes either got high paying job cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Sounds like you may need some more treatment f...</td>\n",
       "      <td>1451606532</td>\n",
       "      <td>sounds like may need treatment anxiety crucial...</td>\n",
       "      <td>[sound, like, may, need, treatment, anxiety, c...</td>\n",
       "      <td>sound like may need treatment anxiety crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>hack her phone or fb, its the only way you'll ...</td>\n",
       "      <td>1451606539</td>\n",
       "      <td>hack her phone fb way youll truly know think h...</td>\n",
       "      <td>[hack, her, phone, fb, way, youll, truly, know...</td>\n",
       "      <td>hack her phone fb way youll truly know think h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574679</th>\n",
       "      <td>technews</td>\n",
       "      <td>PLEASE! I GET LIKE 3Mb/s I NEEEED THIS</td>\n",
       "      <td>1483147728</td>\n",
       "      <td>please get like 3mbs neeeed</td>\n",
       "      <td>[please, get, like, 3mbs, neeeed]</td>\n",
       "      <td>please get like 3mbs neeeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574680</th>\n",
       "      <td>technews</td>\n",
       "      <td>Took some screenshots if it gets removed avail...</td>\n",
       "      <td>1483189543</td>\n",
       "      <td>took screenshots gets removed available httpii...</td>\n",
       "      <td>[took, screenshots, get, removed, available, h...</td>\n",
       "      <td>took screenshots get removed available httpiim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574681</th>\n",
       "      <td>technews</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1483199435</td>\n",
       "      <td>removed</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574682</th>\n",
       "      <td>technews</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>1483205392</td>\n",
       "      <td>best tldr could make originalhttpwwwreuterscom...</td>\n",
       "      <td>[best, tldr, could, make, originalhttpwwwreute...</td>\n",
       "      <td>best tldr could make originalhttpwwwreuterscom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574683</th>\n",
       "      <td>technews</td>\n",
       "      <td>Good, LCD prices have been stagnant too long d...</td>\n",
       "      <td>1483215756</td>\n",
       "      <td>good lcd prices stagnant long due lack competi...</td>\n",
       "      <td>[good, lcd, price, stagnant, long, due, lack, ...</td>\n",
       "      <td>good lcd price stagnant long due lack competit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574684 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                            comment  \\\n",
       "0       TheRedPill     Why the fuck would you be friends with an ex?    \n",
       "1       TheRedPill  Great story full of RP truths. Thanks. Conside...   \n",
       "2       TheRedPill  Lets suss this out. \\n\\nFor one; she's either ...   \n",
       "3       TheRedPill  Sounds like you may need some more treatment f...   \n",
       "4       TheRedPill  hack her phone or fb, its the only way you'll ...   \n",
       "...            ...                                                ...   \n",
       "574679    technews             PLEASE! I GET LIKE 3Mb/s I NEEEED THIS   \n",
       "574680    technews  Took some screenshots if it gets removed avail...   \n",
       "574681    technews                                          [removed]   \n",
       "574682    technews  This is the best tl;dr I could make, [original...   \n",
       "574683    technews  Good, LCD prices have been stagnant too long d...   \n",
       "\n",
       "        time created                                       cleaned_text  \\\n",
       "0         1451606442                              fuck would friends ex   \n",
       "1         1451606479  great story full rp truths thanks consider mak...   \n",
       "2         1451606497  lets suss one shes either got high paying job ...   \n",
       "3         1451606532  sounds like may need treatment anxiety crucial...   \n",
       "4         1451606539  hack her phone fb way youll truly know think h...   \n",
       "...              ...                                                ...   \n",
       "574679    1483147728                        please get like 3mbs neeeed   \n",
       "574680    1483189543  took screenshots gets removed available httpii...   \n",
       "574681    1483199435                                            removed   \n",
       "574682    1483205392  best tldr could make originalhttpwwwreuterscom...   \n",
       "574683    1483215756  good lcd prices stagnant long due lack competi...   \n",
       "\n",
       "                                                   lemmas  \\\n",
       "0                               [fuck, would, friend, ex]   \n",
       "1       [great, story, full, rp, truth, thanks, consid...   \n",
       "2       [let, sus, one, shes, either, got, high, payin...   \n",
       "3       [sound, like, may, need, treatment, anxiety, c...   \n",
       "4       [hack, her, phone, fb, way, youll, truly, know...   \n",
       "...                                                   ...   \n",
       "574679                  [please, get, like, 3mbs, neeeed]   \n",
       "574680  [took, screenshots, get, removed, available, h...   \n",
       "574681                                          [removed]   \n",
       "574682  [best, tldr, could, make, originalhttpwwwreute...   \n",
       "574683  [good, lcd, price, stagnant, long, due, lack, ...   \n",
       "\n",
       "                                               lemmas_str  \n",
       "0                                    fuck would friend ex  \n",
       "1       great story full rp truth thanks consider maki...  \n",
       "2       let sus one shes either got high paying job cl...  \n",
       "3       sound like may need treatment anxiety crucial ...  \n",
       "4       hack her phone fb way youll truly know think h...  \n",
       "...                                                   ...  \n",
       "574679                        please get like 3mbs neeeed  \n",
       "574680  took screenshots get removed available httpiim...  \n",
       "574681                                            removed  \n",
       "574682  best tldr could make originalhttpwwwreuterscom...  \n",
       "574683  good lcd price stagnant long due lack competit...  \n",
       "\n",
       "[574684 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in ./anaconda3/lib/python3.7/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Negative\n",
    "comments_corpus['neg'] = [analyzer.polarity_scores(v)['neg'] for v in comments_corpus['lemmas_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound\n",
    "comments_corpus['compound'] = [analyzer.polarity_scores(v)['compound'] for v in comments_corpus['lemmas_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive\n",
    "comments_corpus['pos'] = [analyzer.polarity_scores(v)['pos'] for v in comments_corpus['lemmas_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>time created</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lemmas_str</th>\n",
       "      <th>neg</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Why the fuck would you be friends with an ex?</td>\n",
       "      <td>1451606442</td>\n",
       "      <td>fuck would friends ex</td>\n",
       "      <td>[fuck, would, friend, ex]</td>\n",
       "      <td>fuck would friend ex</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Great story full of RP truths. Thanks. Conside...</td>\n",
       "      <td>1451606479</td>\n",
       "      <td>great story full rp truths thanks consider mak...</td>\n",
       "      <td>[great, story, full, rp, truth, thanks, consid...</td>\n",
       "      <td>great story full rp truth thanks consider maki...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Lets suss this out. \\n\\nFor one; she's either ...</td>\n",
       "      <td>1451606497</td>\n",
       "      <td>lets suss one shes either got high paying job ...</td>\n",
       "      <td>[let, sus, one, shes, either, got, high, payin...</td>\n",
       "      <td>let sus one shes either got high paying job cl...</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>Sounds like you may need some more treatment f...</td>\n",
       "      <td>1451606532</td>\n",
       "      <td>sounds like may need treatment anxiety crucial...</td>\n",
       "      <td>[sound, like, may, need, treatment, anxiety, c...</td>\n",
       "      <td>sound like may need treatment anxiety crucial ...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheRedPill</td>\n",
       "      <td>hack her phone or fb, its the only way you'll ...</td>\n",
       "      <td>1451606539</td>\n",
       "      <td>hack her phone fb way youll truly know think h...</td>\n",
       "      <td>[hack, her, phone, fb, way, youll, truly, know...</td>\n",
       "      <td>hack her phone fb way youll truly know think h...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574679</th>\n",
       "      <td>technews</td>\n",
       "      <td>PLEASE! I GET LIKE 3Mb/s I NEEEED THIS</td>\n",
       "      <td>1483147728</td>\n",
       "      <td>please get like 3mbs neeeed</td>\n",
       "      <td>[please, get, like, 3mbs, neeeed]</td>\n",
       "      <td>please get like 3mbs neeeed</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574680</th>\n",
       "      <td>technews</td>\n",
       "      <td>Took some screenshots if it gets removed avail...</td>\n",
       "      <td>1483189543</td>\n",
       "      <td>took screenshots gets removed available httpii...</td>\n",
       "      <td>[took, screenshots, get, removed, available, h...</td>\n",
       "      <td>took screenshots get removed available httpiim...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574681</th>\n",
       "      <td>technews</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1483199435</td>\n",
       "      <td>removed</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>removed</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574682</th>\n",
       "      <td>technews</td>\n",
       "      <td>This is the best tl;dr I could make, [original...</td>\n",
       "      <td>1483205392</td>\n",
       "      <td>best tldr could make originalhttpwwwreuterscom...</td>\n",
       "      <td>[best, tldr, could, make, originalhttpwwwreute...</td>\n",
       "      <td>best tldr could make originalhttpwwwreuterscom...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574683</th>\n",
       "      <td>technews</td>\n",
       "      <td>Good, LCD prices have been stagnant too long d...</td>\n",
       "      <td>1483215756</td>\n",
       "      <td>good lcd prices stagnant long due lack competi...</td>\n",
       "      <td>[good, lcd, price, stagnant, long, due, lack, ...</td>\n",
       "      <td>good lcd price stagnant long due lack competit...</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574684 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                            comment  \\\n",
       "0       TheRedPill     Why the fuck would you be friends with an ex?    \n",
       "1       TheRedPill  Great story full of RP truths. Thanks. Conside...   \n",
       "2       TheRedPill  Lets suss this out. \\n\\nFor one; she's either ...   \n",
       "3       TheRedPill  Sounds like you may need some more treatment f...   \n",
       "4       TheRedPill  hack her phone or fb, its the only way you'll ...   \n",
       "...            ...                                                ...   \n",
       "574679    technews             PLEASE! I GET LIKE 3Mb/s I NEEEED THIS   \n",
       "574680    technews  Took some screenshots if it gets removed avail...   \n",
       "574681    technews                                          [removed]   \n",
       "574682    technews  This is the best tl;dr I could make, [original...   \n",
       "574683    technews  Good, LCD prices have been stagnant too long d...   \n",
       "\n",
       "        time created                                       cleaned_text  \\\n",
       "0         1451606442                              fuck would friends ex   \n",
       "1         1451606479  great story full rp truths thanks consider mak...   \n",
       "2         1451606497  lets suss one shes either got high paying job ...   \n",
       "3         1451606532  sounds like may need treatment anxiety crucial...   \n",
       "4         1451606539  hack her phone fb way youll truly know think h...   \n",
       "...              ...                                                ...   \n",
       "574679    1483147728                        please get like 3mbs neeeed   \n",
       "574680    1483189543  took screenshots gets removed available httpii...   \n",
       "574681    1483199435                                            removed   \n",
       "574682    1483205392  best tldr could make originalhttpwwwreuterscom...   \n",
       "574683    1483215756  good lcd prices stagnant long due lack competi...   \n",
       "\n",
       "                                                   lemmas  \\\n",
       "0                               [fuck, would, friend, ex]   \n",
       "1       [great, story, full, rp, truth, thanks, consid...   \n",
       "2       [let, sus, one, shes, either, got, high, payin...   \n",
       "3       [sound, like, may, need, treatment, anxiety, c...   \n",
       "4       [hack, her, phone, fb, way, youll, truly, know...   \n",
       "...                                                   ...   \n",
       "574679                  [please, get, like, 3mbs, neeeed]   \n",
       "574680  [took, screenshots, get, removed, available, h...   \n",
       "574681                                          [removed]   \n",
       "574682  [best, tldr, could, make, originalhttpwwwreute...   \n",
       "574683  [good, lcd, price, stagnant, long, due, lack, ...   \n",
       "\n",
       "                                               lemmas_str    neg  compound  \\\n",
       "0                                    fuck would friend ex  0.402   -0.0772   \n",
       "1       great story full rp truth thanks consider maki...  0.000    0.8519   \n",
       "2       let sus one shes either got high paying job cl...  0.076    0.0790   \n",
       "3       sound like may need treatment anxiety crucial ...  0.046    0.8020   \n",
       "4       hack her phone fb way youll truly know think h...  0.000    0.6124   \n",
       "...                                                   ...    ...       ...   \n",
       "574679                        please get like 3mbs neeeed  0.000    0.5859   \n",
       "574680  took screenshots get removed available httpiim...  0.000    0.0000   \n",
       "574681                                            removed  0.000    0.0000   \n",
       "574682  best tldr could make originalhttpwwwreuterscom...  0.000    0.9231   \n",
       "574683  good lcd price stagnant long due lack competit...  0.134    0.1531   \n",
       "\n",
       "          pos  \n",
       "0       0.368  \n",
       "1       0.482  \n",
       "2       0.068  \n",
       "3       0.243  \n",
       "4       0.357  \n",
       "...       ...  \n",
       "574679  0.615  \n",
       "574680  0.000  \n",
       "574681  0.000  \n",
       "574682  0.144  \n",
       "574683  0.169  \n",
       "\n",
       "[574684 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98571262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(tokens):\n",
    "    '''\n",
    "    Counts each distinct token (entity) in a list of tokens\n",
    "    Inputs:\n",
    "        tokens: list of tokens (must be immutable)\n",
    "    Returns: dictionary that maps tokens to counts\n",
    "    '''\n",
    "    count_freq = {}\n",
    "\n",
    "    for el in tokens:\n",
    "    # Check if element is already in the dict\n",
    "        if el in count_freq:\n",
    "        # If it already is, add 1 to count\n",
    "            count_freq[el] += 1\n",
    "        else:\n",
    "        # If it isn't, add one; also initializes key\n",
    "            count_freq[el] = 1\n",
    "\n",
    "    return count_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a82d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the count_tokens function \n",
    "\n",
    "flat_text = sum(comments_corpus['lemmas'], [])\n",
    "\n",
    "frequent_words = count_tokens(flat_text)\n",
    "sorted_frequent = dict(sorted(frequent_words.items(),\n",
    "                           key=lambda item: item[1],\n",
    "                           reverse=True))\n",
    "sorted_frequent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
