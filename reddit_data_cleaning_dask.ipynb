{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "\n",
    "# NOTE: stopwords include pronouns! TODO: make custom stop words list?\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_corpus = pickle.load(open(\"comments_corpus_RC_2011-08.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so', 'i', 'should', 'post', 'a', 'picture', 'of', 'the', 'insides', 'of', 'the', 'books', 'all', 'lined', 'up?']\n",
      "[\"it's\", 'inside', 'daenerys', 'the', 'whole', 'time.']\n",
      "['the', 'wall', \"wasn't\", 'built', 'to', 'keep', '*wildlings*', 'out...']\n",
      "['yeah', \"it's\", 'probably', 'the', 'episode', 'that', 'will', 'need', 'to', 'be', 'the', 'more', 'massively', 'modified', '(in', 'regards', 'of', 'what', 'we', 'will', 'see)', 'so', \"it's\", 'a', 'good', 'thing', 'that', 'grrm', 'is', 'the', 'one', 'calling', 'the', 'shots.']\n",
      "['hah,', 'yeah', 'this', 'is', 'the', 'guy', 'that', 'i', 'saw', 'when', 'researching', 'making', 'my', 'costume.', 'this', 'guy', 'is', 'going', 'to', 'have', 'an', 'amazing', 'costume...', 'i', 'would', 'like', 'to', 'steal', 'it.', '']\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key,comment in comments_corpus['gameofthrones']:\n",
    "    print(key.lower().split(' '))\n",
    "    \n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_corpus_test = {'gameofthrones' : comments_corpus['gameofthrones'][0:20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_comments(comments_corpus):\n",
    "    '''\n",
    "    '''\n",
    "    words_frequency = {}\n",
    "    spec_chars = ['\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "                  \"*\",\"+\",\",\",\"-\",\"/\",\":\",\";\",\"<\",\n",
    "                  \"=\",\">\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "                  \"`\",\"{\",\"|\",\"}\",\"~\",\"–\", '.', '!', \"?\"]\n",
    "\n",
    "    comments_corpus_mod = {}\n",
    "    for subreddit in comments_corpus:\n",
    "        comments_corpus_mod[subreddit] = []\n",
    "    #     words_frequency[subreddit] = Counter()\n",
    "    #     print(\"Working on {} subreddit\".format(subreddit))\n",
    "    #     print(\"The subreddit contains {} comments\".format(len(comments_corpus[subreddit])))\n",
    "        for ind, tup in enumerate(comments_corpus[subreddit]):\n",
    "            comment, time = tup\n",
    "            comment = comment.lower()\n",
    "            comment = comment.replace('\\n','')\n",
    "            comment = unicodedata.normalize('NFKD', comment).encode('ascii', 'ignore').decode('ascii') # I dont know if this is working, and we have to remove links\n",
    "            comment = re.sub('\\d', '', comment)\n",
    "            comment = re.sub(r\"\\W+|_\", \" \", comment)\n",
    "            comments_corpus_mod[subreddit].append((comment, time))\n",
    "            \n",
    "            \n",
    "\n",
    "#             doc_df = list(set(comm_lst.to_list()))\n",
    "#             doc_df = [string.strip() for string in doc_df] \n",
    "#             doc_df = [x.strip(' ') for x in doc_df]\n",
    "    return comments_corpus_mod\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gameofthrones': [('so i should post a picture of the insides of the books all lined up ',\n",
       "   '1312156828'),\n",
       "  ('it s inside daenerys the whole time ', '1312156896'),\n",
       "  ('the wall wasn t built to keep wildlings out ', '1312157007'),\n",
       "  ('yeah it s probably the episode that will need to be the more massively modified in regards of what we will see so it s a good thing that grrm is the one calling the shots ',\n",
       "   '1312157061'),\n",
       "  ('hah yeah this is the guy that i saw when researching making my costume this guy is going to have an amazing costume i would like to steal it ',\n",
       "   '1312157198'),\n",
       "  ('that one and this one http www youtube com watch v t agdfic are way better cut and narrated though ',\n",
       "   '1312157591'),\n",
       "  (' acok b it is theons uncle he is the one who meets theon when he returns to pyke and he takes him back to their castle to meet his father he is usually called damphair and he is a priest ',\n",
       "   '1312157889'),\n",
       "  ('what do we get more of people posting their books or people posting about people posting their books how about we stop both ',\n",
       "   '1312157980'),\n",
       "  ('with hints of stratego looks to be rather fun ', '1312158136'),\n",
       "  ('i hope he budgeted in a spray tan ', '1312158180'),\n",
       "  ('the mother to child milk action might not work but i don t see why dragons don t fit the rest of the qualification ',\n",
       "   '1312158197'),\n",
       "  ('i don t think you ll find anyone in this subreddit to disagree with ',\n",
       "   '1312158259'),\n",
       "  ('i m now suspicious of the bewbs also ', '1312158277'),\n",
       "  ('there is speculation speculation that he is not ned s bastard but actually rhaegar targaryean and lyanna stark s and a lot of evidence backs it up so that would serve him marrying dany ',\n",
       "   '1312158402'),\n",
       "  ('melisandre is always telling him to keep ghost close and jon is a warg he becomes ghost at the least if his body dies ',\n",
       "   '1312158475'),\n",
       "  (' i like wondering what valar morghulis means i still don t know yet but i have some ideas though it might piss off viewers to have to wait until whenever to learn about it i ain t clicking on that because i m only pages into asos ',\n",
       "   '1312158527'),\n",
       "  (' gt what scenes from book do you think would make it into season and vice versa i think the final scene of season will be the prologue from book extremely early asos spoiler b when the night s watch blow their horns three times to announce that the others are coming and people start pissing their pants ',\n",
       "   '1312158698'),\n",
       "  (' first book b except dragons have been gone for something like a hundred years and they ve had long seasons still remember the books come on the heels of the long summer and there weren t dragons until the end of it ',\n",
       "   '1312158708'),\n",
       "  ('i always lose it when they start playing salsbury hill ', '1312158710'),\n",
       "  ('all its missing is the cheesy laugh track ', '1312158771')]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments(comments_corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = 'That logic doesn\\'t work though.\\nFeminism isn\\'t simply \"equality of men and women\". Hell even if it was that is such a vague statement (as opposed to \"doctor who specializes in skin conditions). For example, what do you mean by equality? Equality of opportunity? Equality of outcome? Equality before the law?\\n\\nNot'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That',\n",
       " 'logic',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'work',\n",
       " 'though',\n",
       " 'Feminism',\n",
       " 'isn',\n",
       " 't',\n",
       " 'simply',\n",
       " 'equality',\n",
       " 'of',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " 'Hell',\n",
       " 'even',\n",
       " 'if',\n",
       " 'it',\n",
       " 'was',\n",
       " 'that',\n",
       " 'is',\n",
       " 'such',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'statement',\n",
       " 'as',\n",
       " 'opposed',\n",
       " 'to',\n",
       " 'doctor',\n",
       " 'who',\n",
       " 'specializes',\n",
       " 'in',\n",
       " 'skin',\n",
       " 'conditions',\n",
       " 'For',\n",
       " 'example',\n",
       " 'what',\n",
       " 'do',\n",
       " 'you',\n",
       " 'mean',\n",
       " 'by',\n",
       " 'equality',\n",
       " 'Equality',\n",
       " 'of',\n",
       " 'opportunity',\n",
       " 'Equality',\n",
       " 'of',\n",
       " 'outcome',\n",
       " 'Equality',\n",
       " 'before',\n",
       " 'the',\n",
       " 'law',\n",
       " 'Not']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment = re.sub(r\"\\W+|_\", \" \", test_comment)\n",
    "\n",
    "test_comment = test_comment.split()\n",
    "\n",
    "test_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_string = '''',#,%,&,',(,),*,+,,,-,/,:,;,<,=,>,@,[,\\\\,],^,_,`,{,|,},~,–, ., !, ?'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
