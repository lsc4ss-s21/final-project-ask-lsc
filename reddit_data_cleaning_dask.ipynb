{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_yarn import YarnCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/kaylah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "# NOTE: stopwords include pronouns! TODO: make custom stop words list?\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cluster where each worker has 1 cores and 4 GiB of memory:\n",
    "cluster = YarnCluster(environment=\"/home/hadoop/environment.tar.gz\",\n",
    "                      worker_vcores = 1,\n",
    "                      worker_memory = \"4GiB\"\n",
    "                      )\n",
    "\n",
    "# Scale cluster out to 8 such workers:\n",
    "cluster.scale(8)\n",
    "\n",
    "# Connect to the cluster (before proceeding, you should wait for workers to be registered by the dask scheduler, as below):\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning adatped from: https://github.com/xssChauhan/Blog-Posts/blob/master/dask-text-processing/Dask%20Text%20Processing.ipynb\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_comments(comment):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    comment = comment.replace('\\n','')\n",
    "    comment = nltk.word_tokenize(comment)\n",
    "    comment = list(filter(lambda word: word.isalnum(), comment))\n",
    "    comment = [word.lower() for word in comment]\n",
    "\n",
    "    comment = unicodedata.normalize('NFKD', comment).encode('ascii', 'ignore').decode('ascii') # I dont know if this is working, and we have to remove links\n",
    "    #             comment = re.sub('\\d', '', comment)\n",
    "    #             comment = re.sub(r\"\\W+|_\", \" \", comment)\n",
    "\n",
    "    return comment\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "#stop_words.remove(['she', 'her', 'hers', 'herself']) # for topic clustering?\n",
    "\n",
    "\n",
    "def remove_stopwords(comment):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    no_stop_words = list(filter(lambda comment: comment not in stop_words, comment))\n",
    "    return no_stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize(comment):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    word_join = nlp(' '.join(comment))\n",
    "    lemmatized = [word.lemma_ for word in word_join]\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    df[\"cleaned_text\"] = df.comment.map(clean_comments).map(remove_stopwords).map(lemmatize)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_corpus = pickle.load(open(\"comments_corpus_RC_2011-08.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "\n",
    "# change corpus to dataframe\n",
    "subreddit_lst = []\n",
    "comment_lst = []\n",
    "time_lst = []\n",
    "for key in comments_corpus:\n",
    "    for comment, time in comments_corpus[key]:\n",
    "        subreddit_lst.append(key)\n",
    "        comment_lst.append(comment)\n",
    "        time_lst.append(time)\n",
    "        \n",
    "comments_df = pd.DataFrame(list(zip(subreddit_lst, comment_lst, time_lst)),\n",
    "                           columns = ['subreddit', 'comment', 'time created'])\n",
    "\n",
    "#convert to dask dataframe\n",
    "dask_dataframe = ddf.from_pandas(comments_df, npartitions=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "result = dask_dataframe.map_partitions(clean_text, meta=df)\n",
    "df = result.compute()\n",
    "t1 = time.time()\n",
    "print(\"Time to process with Dask {}\".format(t1-t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment</th>\n",
       "      <th>time created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>So I should post a picture of the insides of t...</td>\n",
       "      <td>1312156828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>It's inside Daenerys the whole time.</td>\n",
       "      <td>1312156896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>The Wall wasn't built to keep *wildlings* out...</td>\n",
       "      <td>1312157007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Yeah it's probably the episode that will need ...</td>\n",
       "      <td>1312157061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Hah, yeah this is the guy that I saw when rese...</td>\n",
       "      <td>1312157198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>That one and [this one](http://www.youtube.com...</td>\n",
       "      <td>1312157591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[aCoK](/b \"It is Theons uncle, he is the one w...</td>\n",
       "      <td>1312157889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>What do we get more of? People posting their b...</td>\n",
       "      <td>1312157980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>with hints of stratego, looks to be rather fun.</td>\n",
       "      <td>1312158136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>i hope he budgeted in a spray tan.</td>\n",
       "      <td>1312158180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>The mother to child milk action might not work...</td>\n",
       "      <td>1312158197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>I don't think you'll find anyone in this subre...</td>\n",
       "      <td>1312158259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>I'm now suspicious of the bewbs also.</td>\n",
       "      <td>1312158277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>There is speculation [Speculation](/? \" that h...</td>\n",
       "      <td>1312158402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>Melisandre is always telling him to keep Ghost...</td>\n",
       "      <td>1312158475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>1- I like wondering what valar morghulis means...</td>\n",
       "      <td>1312158527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>&amp;gt;What scenes from book 3 do you think would...</td>\n",
       "      <td>1312158698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>[First book](/b \"Except, dragons have been gon...</td>\n",
       "      <td>1312158708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>I always lose it when they start playing Salsb...</td>\n",
       "      <td>1312158710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>All its missing is the cheesy laugh track.</td>\n",
       "      <td>1312158771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                            comment  \\\n",
       "0   gameofthrones  So I should post a picture of the insides of t...   \n",
       "1   gameofthrones               It's inside Daenerys the whole time.   \n",
       "2   gameofthrones   The Wall wasn't built to keep *wildlings* out...   \n",
       "3   gameofthrones  Yeah it's probably the episode that will need ...   \n",
       "4   gameofthrones  Hah, yeah this is the guy that I saw when rese...   \n",
       "5   gameofthrones  That one and [this one](http://www.youtube.com...   \n",
       "6   gameofthrones  [aCoK](/b \"It is Theons uncle, he is the one w...   \n",
       "7   gameofthrones  What do we get more of? People posting their b...   \n",
       "8   gameofthrones    with hints of stratego, looks to be rather fun.   \n",
       "9   gameofthrones                 i hope he budgeted in a spray tan.   \n",
       "10  gameofthrones  The mother to child milk action might not work...   \n",
       "11  gameofthrones  I don't think you'll find anyone in this subre...   \n",
       "12  gameofthrones              I'm now suspicious of the bewbs also.   \n",
       "13  gameofthrones  There is speculation [Speculation](/? \" that h...   \n",
       "14  gameofthrones  Melisandre is always telling him to keep Ghost...   \n",
       "15  gameofthrones  1- I like wondering what valar morghulis means...   \n",
       "16  gameofthrones  &gt;What scenes from book 3 do you think would...   \n",
       "17  gameofthrones  [First book](/b \"Except, dragons have been gon...   \n",
       "18  gameofthrones  I always lose it when they start playing Salsb...   \n",
       "19  gameofthrones         All its missing is the cheesy laugh track.   \n",
       "\n",
       "   time created  \n",
       "0    1312156828  \n",
       "1    1312156896  \n",
       "2    1312157007  \n",
       "3    1312157061  \n",
       "4    1312157198  \n",
       "5    1312157591  \n",
       "6    1312157889  \n",
       "7    1312157980  \n",
       "8    1312158136  \n",
       "9    1312158180  \n",
       "10   1312158197  \n",
       "11   1312158259  \n",
       "12   1312158277  \n",
       "13   1312158402  \n",
       "14   1312158475  \n",
       "15   1312158527  \n",
       "16   1312158698  \n",
       "17   1312158708  \n",
       "18   1312158710  \n",
       "19   1312158771  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_lst = []\n",
    "comment_lst = []\n",
    "time_lst = []\n",
    "for key in comments_corpus_test:\n",
    "    for comment, time in comments_corpus_test[key]:\n",
    "        subreddit_lst.append(key)\n",
    "        comment_lst.append(comment)\n",
    "        time_lst.append(time)\n",
    "        \n",
    "comments_df = pd.DataFrame(list(zip(subreddit_lst, comment_lst, time_lst)),\n",
    "                           columns = ['subreddit', 'comment', 'time created'])\n",
    "\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so', 'i', 'should', 'post', 'a', 'picture', 'of', 'the', 'insides', 'of', 'the', 'books', 'all', 'lined', 'up?']\n",
      "[\"it's\", 'inside', 'daenerys', 'the', 'whole', 'time.']\n",
      "['the', 'wall', \"wasn't\", 'built', 'to', 'keep', '*wildlings*', 'out...']\n",
      "['yeah', \"it's\", 'probably', 'the', 'episode', 'that', 'will', 'need', 'to', 'be', 'the', 'more', 'massively', 'modified', '(in', 'regards', 'of', 'what', 'we', 'will', 'see)', 'so', \"it's\", 'a', 'good', 'thing', 'that', 'grrm', 'is', 'the', 'one', 'calling', 'the', 'shots.']\n",
      "['hah,', 'yeah', 'this', 'is', 'the', 'guy', 'that', 'i', 'saw', 'when', 'researching', 'making', 'my', 'costume.', 'this', 'guy', 'is', 'going', 'to', 'have', 'an', 'amazing', 'costume...', 'i', 'would', 'like', 'to', 'steal', 'it.', '']\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key,comment in comments_corpus['gameofthrones']:\n",
    "    print(key.lower().split(' '))\n",
    "    \n",
    "    counter += 1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_corpus_test = {'gameofthrones' : comments_corpus['gameofthrones'][0:20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gameofthrones': [(['so',\n",
       "    'i',\n",
       "    'should',\n",
       "    'post',\n",
       "    'a',\n",
       "    'picture',\n",
       "    'of',\n",
       "    'the',\n",
       "    'insides',\n",
       "    'of',\n",
       "    'the',\n",
       "    'books',\n",
       "    'all',\n",
       "    'lined',\n",
       "    'up'],\n",
       "   '1312156828'),\n",
       "  (['it', 'inside', 'daenerys', 'the', 'whole', 'time'], '1312156896'),\n",
       "  (['the', 'wall', 'was', 'built', 'to', 'keep', 'wildlings', 'out'],\n",
       "   '1312157007'),\n",
       "  (['yeah',\n",
       "    'it',\n",
       "    'probably',\n",
       "    'the',\n",
       "    'episode',\n",
       "    'that',\n",
       "    'will',\n",
       "    'need',\n",
       "    'to',\n",
       "    'be',\n",
       "    'the',\n",
       "    'more',\n",
       "    'massively',\n",
       "    'modified',\n",
       "    'in',\n",
       "    'regards',\n",
       "    'of',\n",
       "    'what',\n",
       "    'we',\n",
       "    'will',\n",
       "    'see',\n",
       "    'so',\n",
       "    'it',\n",
       "    'a',\n",
       "    'good',\n",
       "    'thing',\n",
       "    'that',\n",
       "    'grrm',\n",
       "    'is',\n",
       "    'the',\n",
       "    'one',\n",
       "    'calling',\n",
       "    'the',\n",
       "    'shots'],\n",
       "   '1312157061'),\n",
       "  (['hah',\n",
       "    'yeah',\n",
       "    'this',\n",
       "    'is',\n",
       "    'the',\n",
       "    'guy',\n",
       "    'that',\n",
       "    'i',\n",
       "    'saw',\n",
       "    'when',\n",
       "    'researching',\n",
       "    'making',\n",
       "    'my',\n",
       "    'costume',\n",
       "    'this',\n",
       "    'guy',\n",
       "    'is',\n",
       "    'going',\n",
       "    'to',\n",
       "    'have',\n",
       "    'an',\n",
       "    'amazing',\n",
       "    'costume',\n",
       "    'i',\n",
       "    'would',\n",
       "    'like',\n",
       "    'to',\n",
       "    'steal',\n",
       "    'it'],\n",
       "   '1312157198'),\n",
       "  (['that',\n",
       "    'one',\n",
       "    'and',\n",
       "    'this',\n",
       "    'one',\n",
       "    'http',\n",
       "    'are',\n",
       "    'way',\n",
       "    'better',\n",
       "    'cut',\n",
       "    'and',\n",
       "    'narrated',\n",
       "    'though'],\n",
       "   '1312157591'),\n",
       "  (['acok',\n",
       "    'it',\n",
       "    'is',\n",
       "    'theons',\n",
       "    'uncle',\n",
       "    'he',\n",
       "    'is',\n",
       "    'the',\n",
       "    'one',\n",
       "    'who',\n",
       "    'meets',\n",
       "    'theon',\n",
       "    'when',\n",
       "    'he',\n",
       "    'returns',\n",
       "    'to',\n",
       "    'pyke',\n",
       "    'and',\n",
       "    'he',\n",
       "    'takes',\n",
       "    'him',\n",
       "    'back',\n",
       "    'to',\n",
       "    'their',\n",
       "    'castle',\n",
       "    'to',\n",
       "    'meet',\n",
       "    'his',\n",
       "    'father',\n",
       "    'he',\n",
       "    'is',\n",
       "    'usually',\n",
       "    'called',\n",
       "    'damphair',\n",
       "    'and',\n",
       "    'he',\n",
       "    'is',\n",
       "    'a',\n",
       "    'priest'],\n",
       "   '1312157889'),\n",
       "  (['what',\n",
       "    'do',\n",
       "    'we',\n",
       "    'get',\n",
       "    'more',\n",
       "    'of',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'their',\n",
       "    'books',\n",
       "    'or',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'about',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'their',\n",
       "    'books',\n",
       "    'how',\n",
       "    'about',\n",
       "    'we',\n",
       "    'stop',\n",
       "    'both'],\n",
       "   '1312157980'),\n",
       "  (['with', 'hints', 'of', 'stratego', 'looks', 'to', 'be', 'rather', 'fun'],\n",
       "   '1312158136'),\n",
       "  (['i', 'hope', 'he', 'budgeted', 'in', 'a', 'spray', 'tan'], '1312158180'),\n",
       "  (['the',\n",
       "    'mother',\n",
       "    'to',\n",
       "    'child',\n",
       "    'milk',\n",
       "    'action',\n",
       "    'might',\n",
       "    'not',\n",
       "    'work',\n",
       "    'but',\n",
       "    'i',\n",
       "    'do',\n",
       "    'see',\n",
       "    'why',\n",
       "    'dragons',\n",
       "    'do',\n",
       "    'fit',\n",
       "    'the',\n",
       "    'rest',\n",
       "    'of',\n",
       "    'the',\n",
       "    'qualification'],\n",
       "   '1312158197'),\n",
       "  (['i',\n",
       "    'do',\n",
       "    'think',\n",
       "    'you',\n",
       "    'find',\n",
       "    'anyone',\n",
       "    'in',\n",
       "    'this',\n",
       "    'subreddit',\n",
       "    'to',\n",
       "    'disagree',\n",
       "    'with'],\n",
       "   '1312158259'),\n",
       "  (['i', 'now', 'suspicious', 'of', 'the', 'bewbs', 'also'], '1312158277'),\n",
       "  (['there',\n",
       "    'is',\n",
       "    'speculation',\n",
       "    'speculation',\n",
       "    'that',\n",
       "    'he',\n",
       "    'is',\n",
       "    'not',\n",
       "    'ned',\n",
       "    'bastard',\n",
       "    'but',\n",
       "    'actually',\n",
       "    'rhaegar',\n",
       "    'targaryean',\n",
       "    'and',\n",
       "    'lyanna',\n",
       "    'stark',\n",
       "    'and',\n",
       "    'a',\n",
       "    'lot',\n",
       "    'of',\n",
       "    'evidence',\n",
       "    'backs',\n",
       "    'it',\n",
       "    'up',\n",
       "    'so',\n",
       "    'that',\n",
       "    'would',\n",
       "    'serve',\n",
       "    'him',\n",
       "    'marrying',\n",
       "    'dany'],\n",
       "   '1312158402'),\n",
       "  (['melisandre',\n",
       "    'is',\n",
       "    'always',\n",
       "    'telling',\n",
       "    'him',\n",
       "    'to',\n",
       "    'keep',\n",
       "    'ghost',\n",
       "    'close',\n",
       "    'and',\n",
       "    'jon',\n",
       "    'is',\n",
       "    'a',\n",
       "    'warg',\n",
       "    'he',\n",
       "    'becomes',\n",
       "    'ghost',\n",
       "    'at',\n",
       "    'the',\n",
       "    'least',\n",
       "    'if',\n",
       "    'his',\n",
       "    'body',\n",
       "    'dies'],\n",
       "   '1312158475'),\n",
       "  (['i',\n",
       "    'like',\n",
       "    'wondering',\n",
       "    'what',\n",
       "    'valar',\n",
       "    'morghulis',\n",
       "    'means',\n",
       "    'i',\n",
       "    'still',\n",
       "    'do',\n",
       "    'know',\n",
       "    'yet',\n",
       "    'but',\n",
       "    'i',\n",
       "    'have',\n",
       "    'some',\n",
       "    'ideas',\n",
       "    'though',\n",
       "    'it',\n",
       "    'might',\n",
       "    'piss',\n",
       "    'off',\n",
       "    'viewers',\n",
       "    'to',\n",
       "    'have',\n",
       "    'to',\n",
       "    'wait',\n",
       "    'until',\n",
       "    'whenever',\n",
       "    'to',\n",
       "    'learn',\n",
       "    'about',\n",
       "    'i',\n",
       "    'ai',\n",
       "    'clicking',\n",
       "    'on',\n",
       "    'that',\n",
       "    'because',\n",
       "    'i',\n",
       "    'only',\n",
       "    '150',\n",
       "    'pages',\n",
       "    'into',\n",
       "    'asos'],\n",
       "   '1312158527'),\n",
       "  (['gt',\n",
       "    'what',\n",
       "    'scenes',\n",
       "    'from',\n",
       "    'book',\n",
       "    '3',\n",
       "    'do',\n",
       "    'you',\n",
       "    'think',\n",
       "    'would',\n",
       "    'make',\n",
       "    'it',\n",
       "    'into',\n",
       "    'season',\n",
       "    '2',\n",
       "    'and',\n",
       "    'i',\n",
       "    'think',\n",
       "    'the',\n",
       "    'final',\n",
       "    'scene',\n",
       "    'of',\n",
       "    'season',\n",
       "    '2',\n",
       "    'will',\n",
       "    'be',\n",
       "    'the',\n",
       "    'prologue',\n",
       "    'from',\n",
       "    'book',\n",
       "    '3',\n",
       "    'extremely',\n",
       "    'early',\n",
       "    'asos',\n",
       "    'spoiler',\n",
       "    'when',\n",
       "    'the',\n",
       "    'night',\n",
       "    'watch',\n",
       "    'blow',\n",
       "    'their',\n",
       "    'horns',\n",
       "    'three',\n",
       "    'times',\n",
       "    'to',\n",
       "    'announce',\n",
       "    'that',\n",
       "    'the',\n",
       "    'others',\n",
       "    'are',\n",
       "    'coming',\n",
       "    'and',\n",
       "    'people',\n",
       "    'start',\n",
       "    'pissing',\n",
       "    'their',\n",
       "    'pants'],\n",
       "   '1312158698'),\n",
       "  (['first',\n",
       "    'book',\n",
       "    'except',\n",
       "    'dragons',\n",
       "    'have',\n",
       "    'been',\n",
       "    'gone',\n",
       "    'for',\n",
       "    'something',\n",
       "    'like',\n",
       "    'a',\n",
       "    'hundred',\n",
       "    'years',\n",
       "    'and',\n",
       "    'they',\n",
       "    'had',\n",
       "    'long',\n",
       "    'seasons',\n",
       "    'still',\n",
       "    'remember',\n",
       "    'the',\n",
       "    'books',\n",
       "    'come',\n",
       "    'on',\n",
       "    'the',\n",
       "    'heels',\n",
       "    'of',\n",
       "    'the',\n",
       "    'long',\n",
       "    'summer',\n",
       "    'and',\n",
       "    'there',\n",
       "    'were',\n",
       "    'dragons',\n",
       "    'until',\n",
       "    'the',\n",
       "    'end',\n",
       "    'of',\n",
       "    'it'],\n",
       "   '1312158708'),\n",
       "  (['i',\n",
       "    'always',\n",
       "    'lose',\n",
       "    'it',\n",
       "    'when',\n",
       "    'they',\n",
       "    'start',\n",
       "    'playing',\n",
       "    'salsbury',\n",
       "    'hill'],\n",
       "   '1312158710'),\n",
       "  (['all', 'its', 'missing', 'is', 'the', 'cheesy', 'laugh', 'track'],\n",
       "   '1312158771')]}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_corpus_test = clean_comments(comments_corpus_test)\n",
    "comments_corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post', 'picture', 'insides', 'books', 'lined']\n",
      "['inside', 'daenerys', 'whole', 'time']\n",
      "['wall', 'built', 'keep', 'wildlings']\n",
      "['yeah', 'probably', 'episode', 'need', 'massively', 'modified', 'regards', 'see', 'good', 'thing', 'grrm', 'one', 'calling', 'shots']\n",
      "['hah', 'yeah', 'guy', 'saw', 'researching', 'making', 'costume', 'guy', 'going', 'amazing', 'costume', 'would', 'like', 'steal']\n",
      "['one', 'one', 'http', 'way', 'better', 'cut', 'narrated', 'though']\n",
      "['acok', 'theons', 'uncle', 'one', 'meets', 'theon', 'returns', 'pyke', 'takes', 'back', 'castle', 'meet', 'father', 'usually', 'called', 'damphair', 'priest']\n",
      "['get', 'people', 'posting', 'books', 'people', 'posting', 'people', 'posting', 'books', 'stop']\n",
      "['hints', 'stratego', 'looks', 'rather', 'fun']\n",
      "['hope', 'budgeted', 'spray', 'tan']\n",
      "['mother', 'child', 'milk', 'action', 'might', 'work', 'see', 'dragons', 'fit', 'rest', 'qualification']\n",
      "['think', 'find', 'anyone', 'subreddit', 'disagree']\n",
      "['suspicious', 'bewbs', 'also']\n",
      "['speculation', 'speculation', 'ned', 'bastard', 'actually', 'rhaegar', 'targaryean', 'lyanna', 'stark', 'lot', 'evidence', 'backs', 'would', 'serve', 'marrying', 'dany']\n",
      "['melisandre', 'always', 'telling', 'keep', 'ghost', 'close', 'jon', 'warg', 'becomes', 'ghost', 'least', 'body', 'dies']\n",
      "['like', 'wondering', 'valar', 'morghulis', 'means', 'still', 'know', 'yet', 'ideas', 'though', 'might', 'piss', 'viewers', 'wait', 'whenever', 'learn', 'ai', 'clicking', '150', 'pages', 'asos']\n",
      "['gt', 'scenes', 'book', '3', 'think', 'would', 'make', 'season', '2', 'think', 'final', 'scene', 'season', '2', 'prologue', 'book', '3', 'extremely', 'early', 'asos', 'spoiler', 'night', 'watch', 'blow', 'horns', 'three', 'times', 'announce', 'others', 'coming', 'people', 'start', 'pissing', 'pants']\n",
      "['first', 'book', 'except', 'dragons', 'gone', 'something', 'like', 'hundred', 'years', 'long', 'seasons', 'still', 'remember', 'books', 'come', 'heels', 'long', 'summer', 'dragons', 'end']\n",
      "['always', 'lose', 'start', 'playing', 'salsbury', 'hill']\n",
      "['missing', 'cheesy', 'laugh', 'track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gameofthrones': [(['post', 'picture', 'insides', 'books', 'lined'],\n",
       "   '1312156828'),\n",
       "  (['inside', 'daenerys', 'whole', 'time'], '1312156896'),\n",
       "  (['wall', 'built', 'keep', 'wildlings'], '1312157007'),\n",
       "  (['yeah',\n",
       "    'probably',\n",
       "    'episode',\n",
       "    'need',\n",
       "    'massively',\n",
       "    'modified',\n",
       "    'regards',\n",
       "    'see',\n",
       "    'good',\n",
       "    'thing',\n",
       "    'grrm',\n",
       "    'one',\n",
       "    'calling',\n",
       "    'shots'],\n",
       "   '1312157061'),\n",
       "  (['hah',\n",
       "    'yeah',\n",
       "    'guy',\n",
       "    'saw',\n",
       "    'researching',\n",
       "    'making',\n",
       "    'costume',\n",
       "    'guy',\n",
       "    'going',\n",
       "    'amazing',\n",
       "    'costume',\n",
       "    'would',\n",
       "    'like',\n",
       "    'steal'],\n",
       "   '1312157198'),\n",
       "  (['one', 'one', 'http', 'way', 'better', 'cut', 'narrated', 'though'],\n",
       "   '1312157591'),\n",
       "  (['acok',\n",
       "    'theons',\n",
       "    'uncle',\n",
       "    'one',\n",
       "    'meets',\n",
       "    'theon',\n",
       "    'returns',\n",
       "    'pyke',\n",
       "    'takes',\n",
       "    'back',\n",
       "    'castle',\n",
       "    'meet',\n",
       "    'father',\n",
       "    'usually',\n",
       "    'called',\n",
       "    'damphair',\n",
       "    'priest'],\n",
       "   '1312157889'),\n",
       "  (['get',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'books',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'people',\n",
       "    'posting',\n",
       "    'books',\n",
       "    'stop'],\n",
       "   '1312157980'),\n",
       "  (['hints', 'stratego', 'looks', 'rather', 'fun'], '1312158136'),\n",
       "  (['hope', 'budgeted', 'spray', 'tan'], '1312158180'),\n",
       "  (['mother',\n",
       "    'child',\n",
       "    'milk',\n",
       "    'action',\n",
       "    'might',\n",
       "    'work',\n",
       "    'see',\n",
       "    'dragons',\n",
       "    'fit',\n",
       "    'rest',\n",
       "    'qualification'],\n",
       "   '1312158197'),\n",
       "  (['think', 'find', 'anyone', 'subreddit', 'disagree'], '1312158259'),\n",
       "  (['suspicious', 'bewbs', 'also'], '1312158277'),\n",
       "  (['speculation',\n",
       "    'speculation',\n",
       "    'ned',\n",
       "    'bastard',\n",
       "    'actually',\n",
       "    'rhaegar',\n",
       "    'targaryean',\n",
       "    'lyanna',\n",
       "    'stark',\n",
       "    'lot',\n",
       "    'evidence',\n",
       "    'backs',\n",
       "    'would',\n",
       "    'serve',\n",
       "    'marrying',\n",
       "    'dany'],\n",
       "   '1312158402'),\n",
       "  (['melisandre',\n",
       "    'always',\n",
       "    'telling',\n",
       "    'keep',\n",
       "    'ghost',\n",
       "    'close',\n",
       "    'jon',\n",
       "    'warg',\n",
       "    'becomes',\n",
       "    'ghost',\n",
       "    'least',\n",
       "    'body',\n",
       "    'dies'],\n",
       "   '1312158475'),\n",
       "  (['like',\n",
       "    'wondering',\n",
       "    'valar',\n",
       "    'morghulis',\n",
       "    'means',\n",
       "    'still',\n",
       "    'know',\n",
       "    'yet',\n",
       "    'ideas',\n",
       "    'though',\n",
       "    'might',\n",
       "    'piss',\n",
       "    'viewers',\n",
       "    'wait',\n",
       "    'whenever',\n",
       "    'learn',\n",
       "    'ai',\n",
       "    'clicking',\n",
       "    '150',\n",
       "    'pages',\n",
       "    'asos'],\n",
       "   '1312158527'),\n",
       "  (['gt',\n",
       "    'scenes',\n",
       "    'book',\n",
       "    '3',\n",
       "    'think',\n",
       "    'would',\n",
       "    'make',\n",
       "    'season',\n",
       "    '2',\n",
       "    'think',\n",
       "    'final',\n",
       "    'scene',\n",
       "    'season',\n",
       "    '2',\n",
       "    'prologue',\n",
       "    'book',\n",
       "    '3',\n",
       "    'extremely',\n",
       "    'early',\n",
       "    'asos',\n",
       "    'spoiler',\n",
       "    'night',\n",
       "    'watch',\n",
       "    'blow',\n",
       "    'horns',\n",
       "    'three',\n",
       "    'times',\n",
       "    'announce',\n",
       "    'others',\n",
       "    'coming',\n",
       "    'people',\n",
       "    'start',\n",
       "    'pissing',\n",
       "    'pants'],\n",
       "   '1312158698'),\n",
       "  (['first',\n",
       "    'book',\n",
       "    'except',\n",
       "    'dragons',\n",
       "    'gone',\n",
       "    'something',\n",
       "    'like',\n",
       "    'hundred',\n",
       "    'years',\n",
       "    'long',\n",
       "    'seasons',\n",
       "    'still',\n",
       "    'remember',\n",
       "    'books',\n",
       "    'come',\n",
       "    'heels',\n",
       "    'long',\n",
       "    'summer',\n",
       "    'dragons',\n",
       "    'end'],\n",
       "   '1312158708'),\n",
       "  (['always', 'lose', 'start', 'playing', 'salsbury', 'hill'], '1312158710'),\n",
       "  (['missing', 'cheesy', 'laugh', 'track'], '1312158771')]}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_corpus_test = remove_stopwords(comments_corpus_test)\n",
    "comments_corpus_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
